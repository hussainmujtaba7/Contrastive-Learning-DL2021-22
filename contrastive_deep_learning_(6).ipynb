{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**implementation refrences**:\n",
        "\n",
        "1. https://colab.research.google.com/drive/1D45E5bUK3gQ40YpZo65ozs7hg5l-eo_U?usp=sharing\n",
        "2. https://colab.research.google.com/drive/1oO-Raqge8oGXGNkZQOYTH-je4Xi1SFVI?usp=sharing"
      ],
      "metadata": {
        "id": "DptxGBFmbP_J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports and installations"
      ],
      "metadata": {
        "id": "XvaWgsTxfxDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.12.0 torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116"
      ],
      "metadata": {
        "trusted": true,
        "id": "u-thmrhLZ_fI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyg-lib torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.12.0+cu116.html\n",
        "!pip install plotly\n",
        "!pip install pytorch-metric-learning -q "
      ],
      "metadata": {
        "trusted": true,
        "id": "nty59uVDZ_fM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import ModelNet\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import MLP, PointConv, fps, global_max_pool, radius ,DynamicEdgeConv ,EdgeConv \n",
        "import plotly.express as px\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_metric_learning.losses import NTXentLoss\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import gc"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-20T16:28:42.183915Z",
          "iopub.execute_input": "2022-12-20T16:28:42.184677Z",
          "iopub.status.idle": "2022-12-20T16:28:49.680784Z",
          "shell.execute_reply.started": "2022-12-20T16:28:42.184585Z",
          "shell.execute_reply": "2022-12-20T16:28:49.679597Z"
        },
        "trusted": true,
        "id": "YwTjaJ8lZ_fM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reproducibility stuff\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(0)\n",
        "\n",
        "torch.cuda.manual_seed(0)\n",
        "torch.backends.cudnn.deterministic = True  # Note that this Deterministic mode can have a performance impact\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "trusted": true,
        "id": "m78OsgD1Z_fO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utility Functions\n"
      ],
      "metadata": {
        "id": "sx4lv7YJZ_fO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#train vanilla models\n",
        "def train_model(model,train_loader):\n",
        "    model.train()\n",
        "\n",
        "    total_loss = 0\n",
        "    for data in tqdm(train_loader):\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data)\n",
        "        loss = F.nll_loss(out, data.y)\n",
        "        loss.backward()\n",
        "        total_loss += loss.item() * data.num_graphs\n",
        "        optimizer.step()\n",
        "    return total_loss / len(train_loader)\n",
        "\n",
        "def evaluate_model(model,val_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(val_loader):\n",
        "            data = data.to(device)\n",
        "            out = model(data)\n",
        "            loss = F.nll_loss(out, data.y)\n",
        "            total_loss += loss.item() * data.num_graphs\n",
        "            pred = model(data).max(dim=1)[1]\n",
        "            correct += pred.eq(data.y).sum().item()\n",
        "    return (total_loss / len(val_loader), correct / len(val_loader.dataset))\n",
        "\n",
        "\n",
        "def test_model(model,loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        with torch.no_grad():\n",
        "            pred = model(data).max(dim=1)[1]\n",
        "        correct += pred.eq(data.y).sum().item()\n",
        "    return correct / len(loader.dataset)\n",
        "\n",
        "#train  contrastive learninig\n",
        "def train_contrastive(model,data_loader):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for _, data in enumerate(tqdm(data_loader)):\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        # Get data representations\n",
        "        h_1, h_2, compact_h_1, compact_h_2 = model(data)\n",
        "        # Prepare for loss\n",
        "        embeddings = torch.cat((compact_h_1, compact_h_2))\n",
        "        # The same index corresponds to a positive pair\n",
        "        indices = torch.arange(0, compact_h_1.size(0), device=compact_h_2.device)\n",
        "        labels = torch.cat((indices, indices))\n",
        "        loss = loss_func(embeddings, labels)\n",
        "        loss.backward()\n",
        "        total_loss += loss.item() * data.num_graphs\n",
        "        optimizer.step()\n",
        "    return total_loss / len(data_loader)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-20T16:28:49.694513Z",
          "iopub.execute_input": "2022-12-20T16:28:49.697454Z",
          "iopub.status.idle": "2022-12-20T16:28:49.714004Z",
          "shell.execute_reply.started": "2022-12-20T16:28:49.697395Z",
          "shell.execute_reply": "2022-12-20T16:28:49.713169Z"
        },
        "trusted": true,
        "id": "U4CvlHfhZ_fP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# classes:['bathtub', 'bed', 'chair', 'desk', 'dresser', 'monitor',\n",
        "# 'night_stand', 'sofa', 'table', 'toilet']\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "pre_transform, transform = T.NormalizeScale(), T.SamplePoints(2000)\n",
        "dataset = ModelNet('modelnet/train/', '10', True, transform, pre_transform)\n",
        "test_dataset = ModelNet('modelnet/test/', '10', False, transform, pre_transform)\n",
        "print(\"Number of train Samples: \", len(dataset))\n",
        "print(\"Number of test Samples: \", len(test_dataset))\n",
        "print(\"Sample: \", dataset)\n",
        "print(\"Sample: \", test_dataset)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-20T16:28:51.872771Z",
          "iopub.execute_input": "2022-12-20T16:28:51.873186Z",
          "iopub.status.idle": "2022-12-20T16:42:18.851817Z",
          "shell.execute_reply.started": "2022-12-20T16:28:51.873149Z",
          "shell.execute_reply": "2022-12-20T16:42:18.850806Z"
        },
        "trusted": true,
        "id": "JPwf2jlpZ_fR",
        "outputId": "96b51c78-cf75-4c07-9eeb-2113f2b11204"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "Downloading http://vision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip\nExtracting modelnet/train/ModelNet10.zip\nProcessing...\nDone!\nDownloading http://vision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip\nExtracting modelnet/test/ModelNet10.zip\nProcessing...\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Number of train Samples:  3991\nNumber of test Samples:  908\nSample:  ModelNet10(3991)\nSample:  ModelNet10(908)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Done!\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preprocessing"
      ],
      "metadata": {
        "id": "SzrzDk3ZZ_fS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#data processing for getting 10 percent ,1 percent or all(80 percent of data) for training data and validation data\n",
        "percent_data=0.01 #from [0-0.8]--try for 0.01,0.1,0.8\n",
        "trainData_size=int(len(dataset)*percent_data)\n",
        "testData_size=int(trainData_size * 0.2 )\n",
        "#testData_size = trainData_size # for pre-training on 1 percent of label\n",
        "print(\"Training Size\",trainData_size)\n",
        "indices = np.arange(len(dataset))\n",
        "\n",
        "train_indices, test_indices = train_test_split(indices, train_size = trainData_size,test_size=trainData_size, stratify=dataset.data.y)\n",
        "\n",
        "# Warp into Subsets and DataLoaders\n",
        "train_subset = torch.utils.data.Subset(dataset, train_indices)\n",
        "val_subset = torch.utils.data.Subset(dataset, test_indices)\n",
        "\n",
        "train_loader = DataLoader(train_subset, shuffle=True, batch_size=32)\n",
        "val_loader = DataLoader(val_subset, shuffle=False, batch_size=32)\n",
        "\n",
        "# check distribution of data wrt classes\n",
        "train_targets = []\n",
        "for target in train_loader:\n",
        "    train_targets.append(target.y)\n",
        "train_targets = torch.cat(train_targets)\n",
        "\n",
        "print(train_targets.unique(return_counts=True))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-21T02:18:32.871493Z",
          "iopub.execute_input": "2022-12-21T02:18:32.872713Z",
          "iopub.status.idle": "2022-12-21T02:18:32.953593Z",
          "shell.execute_reply.started": "2022-12-21T02:18:32.872669Z",
          "shell.execute_reply": "2022-12-21T02:18:32.952434Z"
        },
        "trusted": true,
        "id": "-7hQ4YjuZ_fS",
        "outputId": "6c02ddfc-1b22-40e1-8e24-7f934433799f"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Training Size 39\n(tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([1, 5, 9, 2, 2, 4, 2, 7, 4, 3]))\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test dataset\n",
        "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=32)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-21T02:18:36.306478Z",
          "iopub.execute_input": "2022-12-21T02:18:36.307482Z",
          "iopub.status.idle": "2022-12-21T02:18:36.312694Z",
          "shell.execute_reply.started": "2022-12-21T02:18:36.307435Z",
          "shell.execute_reply": "2022-12-21T02:18:36.311699Z"
        },
        "trusted": true,
        "id": "PPEGLgKiZ_fT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plot Some Examples**"
      ],
      "metadata": {
        "id": "yNjiQjogZ_fT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_3d_shape(shape):\n",
        "#     print(\"Number of data points: \", shape.x.shape[0])\n",
        "    x = shape.pos[:, 0]\n",
        "    y = shape.pos[:, 1]\n",
        "    z = shape.pos[:, 2]\n",
        "    fig = px.scatter_3d(x=x, y=y, z=z, opacity=0.3)\n",
        "    fig.show()\n",
        "\n",
        "# Pick a sample\n",
        "sample_idx = 55\n",
        "# plot_3d_shape(train_subset[sample_idx])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-21T02:10:30.172862Z",
          "iopub.execute_input": "2022-12-21T02:10:30.173258Z",
          "iopub.status.idle": "2022-12-21T02:10:30.179740Z",
          "shell.execute_reply.started": "2022-12-21T02:10:30.173224Z",
          "shell.execute_reply": "2022-12-21T02:10:30.178675Z"
        },
        "trusted": true,
        "id": "RM8eVi-bZ_fU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# POINTNET 2\n",
        "\n",
        "Training Pointnet2 uisng all data withoit any pretraining"
      ],
      "metadata": {
        "id": "UMeN3msgZ_fU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SAModule(torch.nn.Module):\n",
        "    def __init__(self, ratio, r, nn):\n",
        "        super().__init__()\n",
        "        self.ratio = ratio\n",
        "        self.r = r\n",
        "        self.conv = PointConv(nn, add_self_loops=True)\n",
        "\n",
        "    def forward(self, x, pos, batch):\n",
        "        idx = fps(pos, batch, ratio=self.ratio)\n",
        "        row, col = radius(pos, pos[idx], self.r, batch, batch[idx],\n",
        "                          max_num_neighbors=64)\n",
        "        edge_index = torch.stack([col, row], dim=0)\n",
        "        x_dst = None if x is None else x[idx]\n",
        "        x = self.conv((x, x_dst), (pos, pos[idx]), edge_index)\n",
        "        pos, batch = pos[idx], batch[idx]\n",
        "        return x, pos, batch\n",
        "\n",
        "\n",
        "class GlobalSAModule(torch.nn.Module):\n",
        "    def __init__(self, nn):\n",
        "        super().__init__()\n",
        "        self.nn = nn\n",
        "\n",
        "    def forward(self, x, pos, batch):\n",
        "        x = self.nn(torch.cat([x, pos], dim=1))\n",
        "        x = global_max_pool(x, batch)\n",
        "        pos = pos.new_zeros((x.size(0), 3))\n",
        "        batch = torch.arange(x.size(0), device=batch.device)\n",
        "        return x, pos, batch\n",
        "\n",
        "\n",
        "class PointNet(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Input channels account for both `pos` and node features.\n",
        "        self.sa1_module = SAModule(0.5, 0.2, MLP([3, 64, 64, 128]))\n",
        "        self.sa2_module = SAModule(0.25, 0.4, MLP([128 + 3, 128, 128, 256]))\n",
        "        self.sa3_module = GlobalSAModule(MLP([256 + 3, 256, 512, 1024]))\n",
        "\n",
        "        self.mlp = MLP([1024, 512, 256, 16], dropout=0.5, norm=None)\n",
        "\n",
        "    def forward(self, data):\n",
        "        sa0_out = (data.x, data.pos, data.batch)\n",
        "        sa1_out = self.sa1_module(*sa0_out)\n",
        "        sa2_out = self.sa2_module(*sa1_out)\n",
        "        sa3_out = self.sa3_module(*sa2_out)\n",
        "        x, pos, batch = sa3_out\n",
        "        return self.mlp(x).log_softmax(dim=-1)\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-21T02:10:33.687058Z",
          "iopub.execute_input": "2022-12-21T02:10:33.687493Z",
          "iopub.status.idle": "2022-12-21T02:10:33.709965Z",
          "shell.execute_reply.started": "2022-12-21T02:10:33.687454Z",
          "shell.execute_reply": "2022-12-21T02:10:33.708777Z"
        },
        "trusted": true,
        "id": "Zs_9VYggZ_fU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PointNetwork = PointNet().to(device)\n",
        "optimizer = torch.optim.Adam(PointNetwork.parameters())\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
        "for epoch in range(0, 50):\n",
        "    loss = train_model(PointNetwork,train_loader)\n",
        "    test_loss,test_acc = evaluate_model(PointNetwork,val_loader)\n",
        "    print(f'Epoch {epoch:03d}, Train_Loss: {loss:.4f},Test_Loss: {test_loss:.4f}, Test_acc: {test_acc:.4f}')\n",
        "    scheduler.step()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-21T02:10:37.835831Z",
          "iopub.execute_input": "2022-12-21T02:10:37.836193Z",
          "iopub.status.idle": "2022-12-21T02:11:17.168057Z",
          "shell.execute_reply.started": "2022-12-21T02:10:37.836164Z",
          "shell.execute_reply": "2022-12-21T02:11:17.167051Z"
        },
        "trusted": true,
        "id": "T9BkLUyTZ_fV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # load saved model\n",
        "# PointNetwork = PointNet().to(device)\n",
        "# PointNetwork.load_state_dict(torch.load('/kaggle/working/PointNet_saved_model_final.pth'))\n",
        "# PointNetwork.eval()"
      ],
      "metadata": {
        "trusted": true,
        "id": "6TljieXyZ_fV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model(PointNetwork,test_loader)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-21T02:12:41.902090Z",
          "iopub.execute_input": "2022-12-21T02:12:41.902489Z",
          "iopub.status.idle": "2022-12-21T02:12:46.598247Z",
          "shell.execute_reply.started": "2022-12-21T02:12:41.902455Z",
          "shell.execute_reply": "2022-12-21T02:12:46.597320Z"
        },
        "trusted": true,
        "id": "lRiMLYMpZ_fV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(PointNetwork.state_dict(), 'PointNet_saved_model_final.pth')"
      ],
      "metadata": {
        "trusted": true,
        "id": "PiKqMfAFZ_fV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del PointNetwork"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-21T01:57:44.375969Z",
          "iopub.execute_input": "2022-12-21T01:57:44.376346Z",
          "iopub.status.idle": "2022-12-21T01:57:44.381923Z",
          "shell.execute_reply.started": "2022-12-21T01:57:44.376315Z",
          "shell.execute_reply": "2022-12-21T01:57:44.380869Z"
        },
        "trusted": true,
        "id": "lLUEByBnZ_fW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dynamic Graph CNN\n",
        "Training EdgeConvNet uisng all data withoit any pretraining"
      ],
      "metadata": {
        "id": "H8dvS3ZMZ_fW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EdgeConvNet(torch.nn.Module):\n",
        "    def __init__(self, out_channels, k=20, aggr='max'):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = DynamicEdgeConv(MLP([2 * 3, 64, 64]), k, aggr)\n",
        "        self.conv2 = DynamicEdgeConv(MLP([2 * 64, 128]), k, aggr)\n",
        "        self.lin1 = Linear(128 + 64, 1024)\n",
        "\n",
        "        self.mlp = MLP([1024, 256, out_channels], dropout=0.5, norm=None)\n",
        "\n",
        "    def forward(self, data):\n",
        "        pos, batch = data.pos, data.batch\n",
        "        x1 = self.conv1(pos, batch)\n",
        "        x2 = self.conv2(x1, batch)\n",
        "        out = self.lin1(torch.cat([x1, x2], dim=1))\n",
        "        out = global_max_pool(out, batch)\n",
        "        out = self.mlp(out)\n",
        "        return F.log_softmax(out, dim=1)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-21T02:18:44.567248Z",
          "iopub.execute_input": "2022-12-21T02:18:44.567858Z",
          "iopub.status.idle": "2022-12-21T02:18:44.575784Z",
          "shell.execute_reply.started": "2022-12-21T02:18:44.567820Z",
          "shell.execute_reply": "2022-12-21T02:18:44.574839Z"
        },
        "trusted": true,
        "id": "wJBJ8828Z_fW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EdgeConvNetwork = EdgeConvNet(10, k=20).to(device)\n",
        "optimizer = torch.optim.Adam(EdgeConvNetwork.parameters())\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
        "for epoch in range(0, 50):\n",
        "    loss = train_model(EdgeConvNetwork,train_loader)\n",
        "    test_loss,test_acc = evaluate_model(EdgeConvNetwork,val_loader)\n",
        "    print(f'Epoch {epoch:03d}, Train_Loss: {loss:.4f},Test_Loss: {test_loss:.4f}, Test_acc: {test_acc:.4f}')\n",
        "    scheduler.step()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-21T02:18:48.120456Z",
          "iopub.execute_input": "2022-12-21T02:18:48.121044Z"
        },
        "trusted": true,
        "id": "5jqWS9OqZ_fW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model(EdgeConvNetwork,test_loader)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-21T02:25:37.812730Z",
          "iopub.execute_input": "2022-12-21T02:25:37.813131Z",
          "iopub.status.idle": "2022-12-21T02:25:55.091324Z",
          "shell.execute_reply.started": "2022-12-21T02:25:37.813096Z",
          "shell.execute_reply": "2022-12-21T02:25:55.090331Z"
        },
        "trusted": true,
        "id": "Ec7rT7dLZ_fW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(EdgeConvNetwork.state_dict(), 'EdgeConvNet_saved_model_final.pth')"
      ],
      "metadata": {
        "trusted": true,
        "id": "-WkD_jwIZ_fX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del EdgeConvNet"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-20T19:52:41.472378Z",
          "iopub.execute_input": "2022-12-20T19:52:41.473231Z",
          "iopub.status.idle": "2022-12-20T19:52:41.897785Z",
          "shell.execute_reply.started": "2022-12-20T19:52:41.473191Z",
          "shell.execute_reply": "2022-12-20T19:52:41.896309Z"
        },
        "trusted": true,
        "id": "w3z9ddijZ_fX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-training using Contrastive approach"
      ],
      "metadata": {
        "id": "atPl7r5xZ_fX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section we apply **Augmentations** to the graph data and train in unsupervised manner using NT-Xent Loss"
      ],
      "metadata": {
        "id": "S2NkJi-tZ_fX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#augmentation set 1\n",
        "# augmentation = T.Compose(\n",
        "#     [\n",
        "#       T.RandomJitter(0.05), \n",
        "#       T.RandomShear(0.1),\n",
        "#       T.RandomRotate(degrees=180),\n",
        "#       T.RandomScale((0.1,0.9))\n",
        "#     ]\n",
        "# )"
      ],
      "metadata": {
        "trusted": true,
        "id": "adYOp5C4Z_fX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#augmentation set 2\n",
        "augmentation = T.Compose([T.RandomJitter(0.03),\n",
        "                          T.RandomFlip(1),\n",
        "                          T.RandomShear(0.2)])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-20T16:55:27.885036Z",
          "iopub.execute_input": "2022-12-20T16:55:27.885461Z",
          "iopub.status.idle": "2022-12-20T16:55:27.890771Z",
          "shell.execute_reply.started": "2022-12-20T16:55:27.885408Z",
          "shell.execute_reply": "2022-12-20T16:55:27.889653Z"
        },
        "trusted": true,
        "id": "MfCIhvk2Z_fX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = next(iter(dataset_loader))\n",
        "# plot_3d_shape(sample[0])\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "-hG8U6N9Z_fX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformered = augmentation(sample)\n",
        "# plot_3d_shape(transformered[0])"
      ],
      "metadata": {
        "trusted": true,
        "id": "VARKAi3UZ_fY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-train Dynamic Graph CNN model"
      ],
      "metadata": {
        "id": "I41p031GZ_fY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EdgeConvNet_ContrasriveNet(torch.nn.Module):\n",
        "    def __init__(self, k=20, aggr='max'):\n",
        "        super().__init__()\n",
        "        # Feature extraction\n",
        "        self.conv1 = DynamicEdgeConv(MLP([2 * 3, 64, 64]), k, aggr)\n",
        "        self.conv2 = DynamicEdgeConv(MLP([2 * 64,128 , 128]), k, aggr)\n",
        "        self.conv3 = DynamicEdgeConv(MLP([2 * 128, 256]), k, aggr)\n",
        "        # Encoder head \n",
        "        self.lin1 = Linear(128 + 64 + 256  , 1024)\n",
        "        # Projection head (See explanation in SimCLRv2)\n",
        "        self.ph1 = Linear(1024, 1024)\n",
        "        self.ph2 = Linear(1024, 512)\n",
        "        self.ph3 = Linear(512 , 64)\n",
        "        \n",
        "\n",
        "    def forward(self, data, train=True):\n",
        "        if train:\n",
        "            # Get 2 augmentations of the batch\n",
        "            augm_1 = augmentation(data)\n",
        "            augm_2 = augmentation(data)\n",
        "\n",
        "            # Extract properties\n",
        "            pos_1, batch_1 = augm_1.pos, augm_1.batch\n",
        "            pos_2, batch_2 = augm_2.pos, augm_2.batch\n",
        "\n",
        "            # Get representations for first augmented view\n",
        "            x1 = self.conv1(pos_1, batch_1)\n",
        "            x2 = self.conv2(x1, batch_1)\n",
        "            x3 = self.conv3(x2, batch_1)\n",
        "            h_points_1 = self.lin1(torch.cat([x1, x2, x3], dim=1))\n",
        "\n",
        "            # Get representations for second augmented view\n",
        "            x1 = self.conv1(pos_2, batch_2)\n",
        "            x2 = self.conv2(x1, batch_2)\n",
        "            x3 = self.conv3(x2, batch_2)\n",
        "            h_points_2 = self.lin1(torch.cat([x1, x2, x3], dim=1))\n",
        "            \n",
        "            # Global representation\n",
        "            h_1 = global_max_pool(h_points_1, batch_1)\n",
        "            h_2 = global_max_pool(h_points_2, batch_2)\n",
        "        else:\n",
        "            x1 = self.conv1(data.pos, data.batch)\n",
        "            x2 = self.conv2(x1, data.batch)\n",
        "            x3 = self.conv3(x2, data.batch)\n",
        "            h_points = self.lin1(torch.cat([x1, x2, x3], dim=1))\n",
        "            return global_max_pool(h_points, data.batch)\n",
        "\n",
        "        # Transformation for loss function\n",
        "        c1_h1= self.ph1(h_1)\n",
        "        c2_h1= F.relu(self.ph2(c1_h1))\n",
        "        compact_h_1= self.ph3(c2_h1)\n",
        "        \n",
        "        c1_h2= self.ph1(h_2)\n",
        "        c2_h2= F.relu(self.ph2(c1_h2))\n",
        "        compact_h_2 = self.ph3(c2_h2)\n",
        "        \n",
        "        return h_1, h_2, compact_h_1, compact_h_2"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-21T00:59:48.734387Z",
          "iopub.execute_input": "2022-12-21T00:59:48.735102Z",
          "iopub.status.idle": "2022-12-21T00:59:48.748225Z",
          "shell.execute_reply.started": "2022-12-21T00:59:48.735065Z",
          "shell.execute_reply": "2022-12-21T00:59:48.747090Z"
        },
        "trusted": true,
        "id": "lpC9DkTaZ_fY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EdgeConvNet_Contrasrive = EdgeConvNet_ContrasriveNet().to(device)\n",
        "optimizer = torch.optim.Adam(EdgeConvNet_Contrasrive.parameters())\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
        "loss_func = NTXentLoss(temperature=0.10)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-20T16:55:39.447461Z",
          "iopub.execute_input": "2022-12-20T16:55:39.448169Z",
          "iopub.status.idle": "2022-12-20T16:55:43.644324Z",
          "shell.execute_reply.started": "2022-12-20T16:55:39.448130Z",
          "shell.execute_reply": "2022-12-20T16:55:43.643213Z"
        },
        "trusted": true,
        "id": "tYRAn31xZ_fY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(0, 15):\n",
        "    loss = train_contrastive(EdgeConvNet_Contrasrive,dataset_loader)\n",
        "    print(f'Epoch {epoch:03d}, Loss: {loss:.4f}')\n",
        "    scheduler.step()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-20T16:55:48.810510Z",
          "iopub.execute_input": "2022-12-20T16:55:48.810874Z",
          "iopub.status.idle": "2022-12-20T18:42:38.211871Z",
          "shell.execute_reply.started": "2022-12-20T16:55:48.810844Z",
          "shell.execute_reply": "2022-12-20T18:42:38.210876Z"
        },
        "trusted": true,
        "id": "yXXsVO7SZ_fY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(EdgeConvNet_Contrasrive.state_dict( ), 'EdgeConvNet_Contrasrive_saved_model_final_aug2.pth')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-20T18:54:40.902231Z",
          "iopub.execute_input": "2022-12-20T18:54:40.902626Z",
          "iopub.status.idle": "2022-12-20T18:54:40.928389Z",
          "shell.execute_reply.started": "2022-12-20T18:54:40.902593Z",
          "shell.execute_reply": "2022-12-20T18:54:40.927428Z"
        },
        "trusted": true,
        "id": "Wj1XfuliZ_fY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del EdgeConvNet_Contrasrive"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-20T19:52:37.758349Z",
          "iopub.execute_input": "2022-12-20T19:52:37.759360Z",
          "iopub.status.idle": "2022-12-20T19:52:37.765243Z",
          "shell.execute_reply.started": "2022-12-20T19:52:37.759319Z",
          "shell.execute_reply": "2022-12-20T19:52:37.764076Z"
        },
        "trusted": true,
        "id": "hypjTqTcZ_fZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-train PointNet2 model"
      ],
      "metadata": {
        "id": "dcERdictZ_fZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PointNetContrasriveNet(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Input channels account for both `pos` and node features.\n",
        "        self.sa1_module = SAModule(0.5, 0.2, MLP([3, 64, 64, 128]))\n",
        "        self.sa2_module = SAModule(0.25, 0.3, MLP([128 + 3, 128, 128, 256]))\n",
        "        self.sa3_module = SAModule(0.25, 0.4, MLP([256 + 3, 256, 256, 512]))\n",
        "        self.sa4_module = GlobalSAModule(MLP([512 + 3, 512, 512, 1024]))\n",
        "        # Projection head (See explanation in SimCLRv2)\n",
        "        self.ph1 = Linear(1024, 1024)\n",
        "        self.ph2 = Linear(1024, 512)\n",
        "        self.ph3 = Linear(512 , 64)\n",
        "        \n",
        "\n",
        "    def forward(self, data, train=True):\n",
        "        if train:\n",
        "            # Get 2 augmentations of the batch\n",
        "            augm_1 = augmentation(data)\n",
        "            augm_2 = augmentation(data)\n",
        "            \n",
        "            #extraxt features from aug1\n",
        "            sa0_out = (augm_1.x, augm_1.pos, augm_1.batch)\n",
        "            sa1_out = self.sa1_module(*sa0_out)\n",
        "            sa2_out = self.sa2_module(*sa1_out)\n",
        "            sa3_out = self.sa3_module(*sa2_out)\n",
        "            sa4_out = self.sa4_module(*sa3_out)\n",
        "            h_1, _ , _ = sa4_out\n",
        "            \n",
        "            #extraxt features from aug1\n",
        "            sa0_out = (augm_2.x, augm_2.pos, augm_2.batch)\n",
        "            sa1_out = self.sa1_module(*sa0_out)\n",
        "            sa2_out = self.sa2_module(*sa1_out)\n",
        "            sa3_out = self.sa3_module(*sa2_out)\n",
        "            sa4_out = self.sa4_module(*sa3_out)\n",
        "            h_2, _, _ = sa4_out\n",
        "            \n",
        "        else:\n",
        "            sa0_out = (data.x, data.pos, data.batch)\n",
        "            sa1_out = self.sa1_module(*sa0_out)\n",
        "            sa2_out = self.sa2_module(*sa1_out)\n",
        "            sa3_out = self.sa3_module(*sa2_out)\n",
        "            sa4_out = self.sa4_module(*sa3_out)\n",
        "            h_points, _ , _ = sa4_out\n",
        "            return h_points\n",
        "\n",
        "        # Transformation for loss function\n",
        "        c1_h1= self.ph1(h_1)\n",
        "        c2_h1= F.relu(self.ph2(c1_h1))\n",
        "        compact_h_1= self.ph3(c2_h1)\n",
        "        \n",
        "        c1_h2= self.ph1(h_2)\n",
        "        c2_h2= F.relu(self.ph2(c1_h2))\n",
        "        compact_h_2 = self.ph3(c2_h2)\n",
        "        \n",
        "        return h_1, h_2, compact_h_1, compact_h_2"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-21T00:59:58.811083Z",
          "iopub.execute_input": "2022-12-21T00:59:58.811536Z",
          "iopub.status.idle": "2022-12-21T00:59:58.832279Z",
          "shell.execute_reply.started": "2022-12-21T00:59:58.811497Z",
          "shell.execute_reply": "2022-12-21T00:59:58.831082Z"
        },
        "trusted": true,
        "id": "YOWcdPrbZ_fZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PointNetContrasrive = PointNetContrasriveNet().to(device)\n",
        "optimizer = torch.optim.Adam(PointNetContrasrive.parameters())\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
        "loss_func = NTXentLoss(temperature=0.10)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-20T18:55:06.214523Z",
          "iopub.execute_input": "2022-12-20T18:55:06.214885Z",
          "iopub.status.idle": "2022-12-20T18:55:06.272668Z",
          "shell.execute_reply.started": "2022-12-20T18:55:06.214852Z",
          "shell.execute_reply": "2022-12-20T18:55:06.271783Z"
        },
        "trusted": true,
        "id": "8QUVh7tGZ_fZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(0, 30):\n",
        "    loss = train_contrastive(PointNetContrasrive,dataset_loader)\n",
        "    print(f'Epoch {epoch:03d}, Loss: {loss:.4f}')\n",
        "    scheduler.step()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-20T19:32:15.487273Z",
          "iopub.execute_input": "2022-12-20T19:32:15.487874Z",
          "iopub.status.idle": "2022-12-20T19:44:51.554781Z",
          "shell.execute_reply.started": "2022-12-20T19:32:15.487838Z",
          "shell.execute_reply": "2022-12-20T19:44:51.553452Z"
        },
        "trusted": true,
        "id": "COA2qIGmZ_fZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(PointNetContrasrive.state_dict(),'PointNetContrasrive_test_final30_aug2.pth')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-20T19:45:14.305455Z",
          "iopub.execute_input": "2022-12-20T19:45:14.305863Z",
          "iopub.status.idle": "2022-12-20T19:45:14.350764Z",
          "shell.execute_reply.started": "2022-12-20T19:45:14.305829Z",
          "shell.execute_reply": "2022-12-20T19:45:14.349217Z"
        },
        "trusted": true,
        "id": "ZcnwAp1wZ_fZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del PointNetContrasrive"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-20T19:53:29.289890Z",
          "iopub.execute_input": "2022-12-20T19:53:29.290269Z",
          "iopub.status.idle": "2022-12-20T19:53:29.295457Z",
          "shell.execute_reply.started": "2022-12-20T19:53:29.290235Z",
          "shell.execute_reply": "2022-12-20T19:53:29.294477Z"
        },
        "trusted": true,
        "id": "vkwSdLYhZ_fZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot and retrive representations from pre-trained models"
      ],
      "metadata": {
        "id": "KLnIFQRnfMd7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get sample batch\n",
        "sample = next(iter(dataset_loader))\n",
        "\n",
        "# Get representations\n",
        "h = PointNetContrasrive(sample.to(device), train=False)\n",
        "h = h.cpu().detach()\n",
        "labels = sample.y.cpu().detach().numpy()\n",
        "\n",
        "# Get low-dimensional t-SNE Embeddings\n",
        "h_embedded = TSNE(n_components=2, learning_rate='auto',\n",
        "                   init='random').fit_transform(h.numpy())\n",
        "\n",
        "# Plot\n",
        "ax = sns.scatterplot(x=h_embedded[:,0], y=h_embedded[:,1], hue=labels, \n",
        "                    alpha=0.5, palette=\"tab20\")\n",
        "\n",
        "# Add labels to be able to identify the data points\n",
        "annotations = list(range(len(h_embedded[:,0])))\n",
        "\n",
        "def label_points(x, y, val, ax):\n",
        "    a = pd.concat({'x': x, 'y': y, 'val': val}, axis=1)\n",
        "    for i, point in a.iterrows():\n",
        "        ax.text(point['x']+.02, point['y'], str(int(point['val'])))\n",
        "\n",
        "label_points(pd.Series(h_embedded[:,0]), \n",
        "            pd.Series(h_embedded[:,1]), \n",
        "            pd.Series(annotations), \n",
        "            plt.gca()) "
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-20T19:45:35.597314Z",
          "iopub.execute_input": "2022-12-20T19:45:35.598250Z",
          "iopub.status.idle": "2022-12-20T19:45:36.544842Z",
          "shell.execute_reply.started": "2022-12-20T19:45:35.598198Z",
          "shell.execute_reply": "2022-12-20T19:45:36.542582Z"
        },
        "trusted": true,
        "id": "7lF82Y2yZ_fZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def sim_matrix(a, b, eps=1e-8):\n",
        "    \"\"\"\n",
        "    Eps for numerical stability\n",
        "    \"\"\"\n",
        "    a_n, b_n = a.norm(dim=1)[:, None], b.norm(dim=1)[:, None]\n",
        "    a_norm = a / torch.max(a_n, eps * torch.ones_like(a_n))\n",
        "    b_norm = b / torch.max(b_n, eps * torch.ones_like(b_n))\n",
        "    sim_mt = torch.mm(a_norm, b_norm.transpose(0, 1))\n",
        "    return sim_mt\n",
        "\n",
        "similarity = sim_matrix(h, h)\n",
        "max_indices = torch.topk(similarity, k=2)[1][:, 1]\n",
        "max_vals  = torch.topk(similarity, k=2)[0][:, 1]\n",
        "\n",
        "# Select index\n",
        "idx = 3\n",
        "similar_idx = max_indices[idx]\n",
        "print(f\"Most similar data point in the embedding space for {idx} is {similar_idx}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-20T19:46:24.402945Z",
          "iopub.execute_input": "2022-12-20T19:46:24.403332Z",
          "iopub.status.idle": "2022-12-20T19:46:24.414172Z",
          "shell.execute_reply.started": "2022-12-20T19:46:24.403298Z",
          "shell.execute_reply": "2022-12-20T19:46:24.413089Z"
        },
        "trusted": true,
        "id": "20RZBTkEZ_fZ",
        "outputId": "833a8af6-09f3-4151-fc84-b42cae84eef1"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Most similar data point in the embedding space for 3 is 16\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_3d_shape(sample[idx].cpu())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-20T19:46:27.415305Z",
          "iopub.execute_input": "2022-12-20T19:46:27.416306Z",
          "iopub.status.idle": "2022-12-20T19:46:27.475575Z",
          "shell.execute_reply.started": "2022-12-20T19:46:27.416267Z",
          "shell.execute_reply": "2022-12-20T19:46:27.474469Z"
        },
        "trusted": true,
        "id": "fva7rv62Z_fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_3d_shape(sample[similar_idx].cpu())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-20T19:46:33.023193Z",
          "iopub.execute_input": "2022-12-20T19:46:33.023602Z",
          "iopub.status.idle": "2022-12-20T19:46:33.084868Z",
          "shell.execute_reply.started": "2022-12-20T19:46:33.023566Z",
          "shell.execute_reply": "2022-12-20T19:46:33.083785Z"
        },
        "trusted": true,
        "id": "2tsrWJ-CZ_fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine_tune on Classification task\n"
      ],
      "metadata": {
        "id": "AFBEb95FZ_fa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.Fine tuning Pointnet Network**"
      ],
      "metadata": {
        "id": "oaOpQU53Z_fa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pointnet_path='/kaggle/input/trained-models/PointNetContrasrive_test_final30.pth'\n",
        "pointnet2_saved=PointNetContrasriveNet().to(device)\n",
        "pointnet2_saved.load_state_dict(torch.load(pointnet_path))\n",
        "pointnet2_saved.ph3 = torch.nn.Linear(512, 10)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-21T01:24:15.737530Z",
          "iopub.execute_input": "2022-12-21T01:24:15.737906Z",
          "iopub.status.idle": "2022-12-21T01:24:15.818421Z",
          "shell.execute_reply.started": "2022-12-21T01:24:15.737875Z",
          "shell.execute_reply": "2022-12-21T01:24:15.817537Z"
        },
        "trusted": true,
        "id": "mF8Dl_8dZ_fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PointNetFineTuned(torch.nn.Module):\n",
        "    def __init__(self,trained_model, ):\n",
        "        super().__init__()\n",
        "        # Feature extraction\n",
        "        self.pre_trained_model = trained_model\n",
        "\n",
        "    def forward(self, data):\n",
        "            out = self.pre_trained_model(data, train=False)\n",
        "            return F.log_softmax(out, dim=1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-21T01:24:17.519226Z",
          "iopub.execute_input": "2022-12-21T01:24:17.519607Z",
          "iopub.status.idle": "2022-12-21T01:24:17.526820Z",
          "shell.execute_reply.started": "2022-12-21T01:24:17.519573Z",
          "shell.execute_reply": "2022-12-21T01:24:17.525456Z"
        },
        "trusted": true,
        "id": "lrq6hAwYZ_fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pointnet_finetuned= PointNetFineTuned(pointnet2_saved).to(device)\n",
        "optimizer = torch.optim.Adam(pointnet_finetuned.parameters())\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
        "for epoch in range(0, 100):\n",
        "    loss = train_model(pointnet_finetuned,train_loader)\n",
        "    test_loss,test_acc = evaluate_model(pointnet_finetuned,val_loader)\n",
        "    print(f'Epoch {epoch:03d}, Train_Loss: {loss:.4f},Test_Loss: {test_loss:.4f}, Test_acc: {test_acc:.4f}')\n",
        "    scheduler.step()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-21T01:24:27.057805Z",
          "iopub.execute_input": "2022-12-21T01:24:27.058176Z",
          "iopub.status.idle": "2022-12-21T01:25:50.800355Z",
          "shell.execute_reply.started": "2022-12-21T01:24:27.058138Z",
          "shell.execute_reply": "2022-12-21T01:25:50.799334Z"
        },
        "trusted": true,
        "id": "UZ2d1mk5Z_fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model(pointnet_finetuned,test_loader)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-21T01:26:43.750452Z",
          "iopub.execute_input": "2022-12-21T01:26:43.751162Z",
          "iopub.status.idle": "2022-12-21T01:26:48.519145Z",
          "shell.execute_reply.started": "2022-12-21T01:26:43.751122Z",
          "shell.execute_reply": "2022-12-21T01:26:48.518146Z"
        },
        "trusted": true,
        "id": "bh1b5wTjZ_fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del pointnet_finetuned"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-21T01:27:22.381019Z",
          "iopub.execute_input": "2022-12-21T01:27:22.381395Z",
          "iopub.status.idle": "2022-12-21T01:27:22.385900Z",
          "shell.execute_reply.started": "2022-12-21T01:27:22.381361Z",
          "shell.execute_reply": "2022-12-21T01:27:22.384940Z"
        },
        "trusted": true,
        "id": "CB8MlYQGZ_fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Finetune Dynamic graph CNN model**"
      ],
      "metadata": {
        "id": "RvuAWdYeZ_fa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "edgeconv_path='/kaggle/input/trained-models/EdgeConvNet_Contrasrive_saved_model_final.pth'\n",
        "EdgeConvNet_saved=EdgeConvNet_ContrasriveNet().to(device)\n",
        "EdgeConvNet_saved.load_state_dict(torch.load(edgeconv_path))\n",
        "EdgeConvNet_saved.ph3 = torch.nn.Linear(512, 10)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-21T01:27:43.521136Z",
          "iopub.execute_input": "2022-12-21T01:27:43.521559Z",
          "iopub.status.idle": "2022-12-21T01:27:43.737947Z",
          "shell.execute_reply.started": "2022-12-21T01:27:43.521523Z",
          "shell.execute_reply": "2022-12-21T01:27:43.736990Z"
        },
        "trusted": true,
        "id": "clCOZX_uZ_fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EdgeConvFineTuned(torch.nn.Module):\n",
        "    def __init__(self,trained_model, ):\n",
        "        super().__init__()\n",
        "        # Feature extraction\n",
        "        self.pre_trained_model = trained_model\n",
        "\n",
        "    def forward(self, data):\n",
        "            out = self.pre_trained_model(data, train=False)\n",
        "            return F.log_softmax(out, dim=1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-21T01:27:45.960959Z",
          "iopub.execute_input": "2022-12-21T01:27:45.961844Z",
          "iopub.status.idle": "2022-12-21T01:27:45.969517Z",
          "shell.execute_reply.started": "2022-12-21T01:27:45.961800Z",
          "shell.execute_reply": "2022-12-21T01:27:45.968356Z"
        },
        "trusted": true,
        "id": "uH9NgURqZ_fb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EdgeConvNet_finetuned=EdgeConvFineTuned(EdgeConvNet_saved).to(device)\n",
        "optimizer = torch.optim.Adam(EdgeConvNet_finetuned.parameters())\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
        "for epoch in range(0, 100):\n",
        "    loss = train_model(EdgeConvNet_finetuned,train_loader)\n",
        "    test_loss,test_acc = evaluate_model(EdgeConvNet_finetuned,val_loader)\n",
        "    print(f'Epoch {epoch:03d}, Train_Loss: {loss:.4f},Test_Loss: {test_loss:.4f}, Test_acc: {test_acc:.4f}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-21T01:40:23.605777Z",
          "iopub.execute_input": "2022-12-21T01:40:23.606141Z",
          "iopub.status.idle": "2022-12-21T01:41:18.804338Z",
          "shell.execute_reply.started": "2022-12-21T01:40:23.606110Z",
          "shell.execute_reply": "2022-12-21T01:41:18.803273Z"
        },
        "trusted": true,
        "id": "UbgxFbRMZ_fb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model(EdgeConvNet_finetuned,test_loader)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-21T01:42:56.339718Z",
          "iopub.execute_input": "2022-12-21T01:42:56.340175Z",
          "iopub.status.idle": "2022-12-21T01:43:39.164354Z",
          "shell.execute_reply.started": "2022-12-21T01:42:56.340115Z",
          "shell.execute_reply": "2022-12-21T01:43:39.163373Z"
        },
        "trusted": true,
        "id": "vS14-mH_Z_fb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#garbage collection\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "S9TvAF0zeUKD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}